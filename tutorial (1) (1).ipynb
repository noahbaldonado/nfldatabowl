{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hAiMbaH7Bga"
      },
      "source": [
        "# Tutorial for using Spiking Neural Networks to Read Lips!\n",
        "\n",
        "By Noah Baldonado\n",
        "\n",
        "You should read the paper https://arxiv.org/pdf/2109.12894:\n",
        "J. K. Eshraghian et al., \"Training Spiking Neural Networks Using Lessons From Deep Learning,\" in Proceedings of the IEEE, vol. 111, no. 9, pp. 1016-1054, Sept. 2023, doi: 10.1109/JPROC.2023.3308088.\n",
        "keywords: {Deep learning;Neuromorphics;Neurons;Biological neural networks;Training;Brain modeling;Australia;Electronic learning;Brain modeling;Tutorials;Deep learning;neural code;neuromorphic;online learning;spiking neural networks (SNNs)},\n",
        "\n",
        "And the paper where this dataset is from: https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.pdf\n",
        "\n",
        "I based a lot of code from [this tutorial](https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/tutorial_7_neuromorphic_datasets.ipynb) by Gregor Lenz and Jason K. Eshraghian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3EVTN7p74TF"
      },
      "source": [
        "## The Problem:\n",
        "These researchers from this paper ([here](https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.pdf)) made an event camera which captures changes brightness for individual pixels at a high rate, instead of a standard, frame based camera which has a lower rate and contains redundant information as it records frames which contain pixels that might not change. They had people say different words, and recorded almost 20,000 samples of people's faces as they said them, in the hopes of using this data to train a model to read lips.\n",
        "\n",
        "After creating this special database, they created and trained a complicated model, a \"Multi-grained Spatio-Temporal Features Perceived Network\" (MSTP) to be able to determine what words people were saying. It used a multi-branch architecture with different frame rates between the two branches, and created a message flow module to connect information between them. Each branch does a 3d convolution, then has several residual blocks, and the branch with more frames has fewer channels. They eventually lead to a sequence model and then it predicts the class.\n",
        "\n",
        "In this tutorial, instead of making this model, you will learn how to use spiking neural networks to do this task! First, you will see a short summary of how spiking neural networks work. Then, for the main part of the tutorial, you will learn how to use them on this dataset (DVS-Lip), to create a spiking neural network to accomplish the task of reading lips. I will then also explore some other options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4oooBE1-l9E"
      },
      "source": [
        "# What Are Spiking Neural Networks?\n",
        "\n",
        "Spiking Neural Networks (SNNs) are neural networks that use spikes to pass along information, just like how the neurons in the brain do with action potentials. This contrasts from a normal artificial neural network (ANN), which passes a value from each neuron as the output. Also, SNNs work over time, just like the brain (so it is very different from a binarized neural network). As neurons receive spikes, their \"membrane potential\" increases, and over time, it decreases. When the membrane potential reaches a threshold, the neuron outputs a spike and the membrane potential jumps back down. The time-based nature of an SNN is similar to an RNN, which keeps a state, the membrane potential, and the output (spike) is fed back in for the reset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEPmKDlg-8wH"
      },
      "source": [
        "# Why are spiking neural networks good?\n",
        "\n",
        "They can be good for efficiency when you combine them with specialized hardware, as well as it's attractive how it more closely emulates how the brain works. For this dataset, we have information how each pixel changes, and the data is over a non-fixed time interval, so it is the perfect chance to use an SNN!\n",
        "\n",
        "# How will this model work?\n",
        "We will convert the data to a set of frames with information for how/if each pixel changes. At each time step, the next frame is fed into the network. For the final outputs, there are a few different ways you could choose to do it, but for this case, it will be with rate encoding, so the class that spikes the most is the predicted class. There are lots more details which will be explained during this tutorial, so now let's start coding!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqlGXG2nC_bb"
      },
      "source": [
        "# Data\n",
        "\n",
        "The first step is to get the data. You will have to download it from [here](https://drive.google.com/file/d/1dBEgtmctTTWJlWnuWxFtk8gfOdVVpkQ0/view) and put it in your google drive. You can edit the following code cells with your file and folder paths. This is how I organized this, and if you do something different then you will need to edit the paths:\n",
        "\n",
        "\n",
        " - In my drive, I have a folder called lip.\n",
        " - In lip, place this tutorial, then make folders called models, data, cache.\n",
        " - In data, make a folder called DVSLip.\n",
        " - In there, place DVS-Lip, the unzipped version of the zip file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTeF2pIzEySU"
      },
      "source": [
        "# Ok the coding tutorial is starting below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gf-TmXVwajV"
      },
      "source": [
        "## Google Drive\n",
        "First, you'll mount your google drive and then go into the lip folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Egmkfy5hDPb8"
      },
      "outputs": [],
      "source": [
        "# This is to mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# This is the google drive folder where I put my notebook, models, data, and everything.\n",
        "# You should make one like this too, and if it has a different name, change it here\n",
        "%cd /content/drive/MyDrive/lip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX5iCGPbwjy5"
      },
      "source": [
        "## Tonic\n",
        "We will use the tonic library to handle the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcrLZTOFDyV7"
      },
      "outputs": [],
      "source": [
        "# We will use tonic to get this dataset and perform things on it.\n",
        "!pip install tonic\n",
        "import tonic\n",
        "from tonic import MemoryCachedDataset\n",
        "# import numpy also\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvueWHkw-6J"
      },
      "source": [
        "Load in the data..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2MYttgdGEwt"
      },
      "outputs": [],
      "source": [
        "# We use tonic.datasets.DVSLip. First, let's just load in the data to see how it is.\n",
        "trainset = tonic.datasets.DVSLip(save_to=\"./data\", train=True)\n",
        "\n",
        "# How many samples?\n",
        "print(f'{len(trainset)} samples in the training dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLcj6xhZxd64"
      },
      "source": [
        "Now, let's look at the first sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFcKinPkHfA7"
      },
      "outputs": [],
      "source": [
        "sample = trainset[0]\n",
        "print(f'The type of a sample is {type(sample)}')\n",
        "print(f'Length: {len(sample)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rxHYCKuxlGU"
      },
      "source": [
        "The first item is the input, the second is the output. First, let's look at the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIhDUaQ1IRnx"
      },
      "outputs": [],
      "source": [
        "sample_input = sample[0]\n",
        "print(f'Type of input: {type(sample_input)}')\n",
        "print(f'Length of input: {len(sample_input)}')\n",
        "print(f'Input: {sample_input}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV1vC-v-xwkC"
      },
      "source": [
        "Ok, so the input for this sample is a numpy array of length 1719. Each element is a tuple, let's look at the first and last ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEEycClRI0af"
      },
      "outputs": [],
      "source": [
        "print(sample_input[0])\n",
        "print(sample_input[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVeJKQ-sJCop"
      },
      "source": [
        "What is this? This tuple is of the form (x, y, p, t). x and y are for what pixel it is. p is the polarity which is for how that pixel is changing. Finally, t is the timestep. You can see here it goes all the way to 728283 for this example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmySc109JV1P"
      },
      "source": [
        "## Now, let's look at the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYMV_ZpdIo48"
      },
      "outputs": [],
      "source": [
        "sample_output = sample[1]\n",
        "print(f'Type of output: {type(sample_output)}')\n",
        "print(f'Output: {sample_output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISIyN7h3JbTd"
      },
      "source": [
        "It is an integer, which is for what class the sample's input corresponds to. Let's look at this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7ZsdZSoJgZ-"
      },
      "outputs": [],
      "source": [
        "classes = trainset.classes\n",
        "print(f'# of classes: {len(classes)}')\n",
        "print(f'Classes: {classes}')\n",
        "print(f'Sample output {sample_output} means class {classes[sample_output]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPoO48hbJxij"
      },
      "source": [
        "Now that you have a sense for how the data is formatted right now, let's load it in for the purpose of our task. Also, we will start working with PyTorch, and with snnTorch, the library for spiking neural networks created by Professor Eshraghian. So let's download and import some things we will need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qazVyxZkyH8N"
      },
      "source": [
        "## Downloading and Importing more\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOK_7oNiKSKX"
      },
      "outputs": [],
      "source": [
        "# pyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# This is not used until we explore other options later\n",
        "import torch.nn.functional as F\n",
        "# This is used for lots of vision related stuff\n",
        "import torchvision\n",
        "# Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# snnTorch\n",
        "!pip install snntorch\n",
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate # for the surrogate function\n",
        "from snntorch import functional as SF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPDZ4PgmL702"
      },
      "source": [
        "# Some hyperparameters\n",
        "Before loading the data we need to set the batch size, so let's also set the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hgcT7qglMFP2"
      },
      "outputs": [],
      "source": [
        "num_epochs = 200\n",
        "# you might need to make the batch size smaller if it's not working this big\n",
        "batch_size = 99"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqN4wmXX4ZsB"
      },
      "source": [
        "Now load the data correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OV9lWgfEjUX"
      },
      "outputs": [],
      "source": [
        "# Get the sensor_size\n",
        "sensor_size = tonic.datasets.DVSLip.sensor_size # should be (128, 128, 2)\n",
        "print(f'Sensor size: {sensor_size}')\n",
        "\n",
        "# The tonic.transforms.Compose is to apply transforms sequentially.\n",
        "# Denoise is used to reduce the noise. If a nearby pixel does not have an event within filter_time from this event, it gets ignored.\n",
        "# ToFrame is super important! The data is formatted right now as a sequence of events which is a tuple, but we want a sequence of frames\n",
        "# The time window is the window across which events are combined to make a single frame. Right now, there are hundreds of thousands of timesteps which you saw when you looked at the last event in the first sample.\n",
        "frame_transform = tonic.transforms.Compose([tonic.transforms.Denoise(filter_time=50000),\n",
        "                                            tonic.transforms.ToFrame(sensor_size=sensor_size,\n",
        "                                                                     time_window=30000)])\n",
        "\n",
        "# Now, we create the trainset (and testset) applying these transforms\n",
        "trainset = tonic.datasets.DVSLip(save_to=\"./data\", transform=frame_transform, train=True)\n",
        "testset = tonic.datasets.DVSLip(save_to=\"./data\", transform=frame_transform, train=False)\n",
        "\n",
        "# Ok now time to switch to pytorch\n",
        "\n",
        "# To convert to float\n",
        "class ToFloat(object):\n",
        "  def __call__(self, sample):\n",
        "    return sample.float()\n",
        "\n",
        "# The first is to convert the input which is a numpy array into a torch tensor.\n",
        "# The next one converts it to float, because the next one after that is normalizing the data and it takes floats.\n",
        "# The last transform is done to make the data normalized\n",
        "torch_transform = torchvision.transforms.Compose([\n",
        "    torch.from_numpy,\n",
        "    ToFloat(),\n",
        "    torchvision.transforms.Normalize((0, 0), (1, 1))\n",
        "    ])\n",
        "\n",
        "# By using this to cache the data, it will speed up training.\n",
        "# It may still take a long time for the first epoch, but then after that, it will go way faster.\n",
        "cached_trainset = MemoryCachedDataset(trainset, transform=torch_transform)\n",
        "cached_testset = MemoryCachedDataset(testset, transform=torch_transform)\n",
        "\n",
        "# Here, we finally create the pytorch dataloaders we wil be using\n",
        "# shuffle is needed because the data is not shuffled at all right now\n",
        "# drop_left is important because otherwise, the late batch will be the wrong size and will cause an error\n",
        "trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True, drop_last=True)\n",
        "# shuffle also used on the testloader beacuse it might take a while to test, and this way you can see more representative results right away\n",
        "testloader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True, drop_last=True)\n",
        "\n",
        "classes = trainset.classes\n",
        "print(f'Training batches: {len(trainloader)}')\n",
        "print(f'Testing batches: {len(testloader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kzzkygSNlho"
      },
      "source": [
        "# Done loading data\n",
        "Great, now, we can get to making the model! The plan is to make a convolutional, spiking neural network. Each neurons remembers its membrane potential from one timestep to the next.\n",
        "\n",
        "At a timestep, the neural network will perform convolutions on the input, after which spiking neurons are applied so it is a spiking neural network. The convolutions will hopefully let the model extract important features. Then, after some convolutions, it's time for a fully connected layer (with spikes as well). Overall, this sequence of convolutions then a fully connected layer should seem very normal, it's just that spikes are added! SNNs and ANNs can have the same architecture, it is just that the neurons are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoWZdDUlOdt9"
      },
      "source": [
        "# How do they learn?\n",
        "You might be wondering, how does the spiking neural network learn?\n",
        "\n",
        "It uses back propagation, just like ANNs, but there's a problem for the derivative of these spikes, because they are either 0 (when there's not a spike) or infinity (when there is a spike)!\n",
        "\n",
        "The solution is a surrogate gradient. On the forward pass, spikes are still used, but for the backward pass, it replaces the spike (the Heaviside function), with a smoothed out version of it. There are several options for this, in this case you will use the fast sigmoid function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PxuzqgRLh0F"
      },
      "source": [
        "## Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsiQUKKXOCZY"
      },
      "source": [
        "Choose the sizes used in the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KwjskMm5OB74"
      },
      "outputs": [],
      "source": [
        "# sizes\n",
        "input_size = sensor_size[0] * sensor_size[1] * sensor_size[2] # 128 * 128 * 2 = 32768\n",
        "# the size of the hidden layers is arbitrary and could be something else too\n",
        "hidden_size = 100\n",
        "output_size = len(classes) # 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clWmtz6hN-Oi"
      },
      "source": [
        "Now, we can define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1CaXrAHdLV_f"
      },
      "outputs": [],
      "source": [
        "# to define one in PyTorch, it is a subclass of nn.Module\n",
        "class SpkNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, beta, spike_grad):\n",
        "    super().__init__()\n",
        "\n",
        "    # Convolutions\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(2, 16, 5)\n",
        "    # after each layer, there is a spiking layer. This is how snnTorch is used to make this a spiking neural network.\n",
        "    # snn.Leaky is for a leaky integrate-and-fire neuron (LIF). This is a standard type of spiking neuron.\n",
        "    # beta is the decay rate, and spike_grad is the function that is used for the gradient.\n",
        "    self.lifc1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "    self.lifc2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 5)\n",
        "    self.lifc3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    # After performing all the convolutions, the result will be of size 9216\n",
        "    self.fc_input_size = 9216\n",
        "\n",
        "    # FC\n",
        "    self.lin1 = nn.Linear(self.fc_input_size, hidden_size)\n",
        "    self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.lin3 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.lin4 = nn.Linear(hidden_size, output_size)\n",
        "    self.lif4 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "  # this defines the forward pass, where it takes an input and outputs the spikes over time\n",
        "  def forward(self, x):\n",
        "    # The spikes will be recorded in spk_rec\n",
        "    spk_rec = []\n",
        "    # Number of frames\n",
        "    num_steps = x.shape[0]\n",
        "\n",
        "    # These keep track of the membrane potential\n",
        "    # init_leaky() is used to initialize the LIF neurons.\n",
        "    mem_c1 = self.lifc1.init_leaky()\n",
        "    mem_c2 = self.lifc2.init_leaky()\n",
        "    mem_c3 = self.lifc3.init_leaky()\n",
        "    mem_1 = self.lif1.init_leaky()\n",
        "    mem_2 = self.lif2.init_leaky()\n",
        "    mem_3 = self.lif3.init_leaky()\n",
        "    mem_4 = self.lif4.init_leaky()\n",
        "\n",
        "    # Now, it will run through the sample, like how an RNN works, and the membrane potentials are kept to be used in the next step.\n",
        "    print(f'/{num_steps}')\n",
        "    for step in range(num_steps):\n",
        "      if (step + 1) % 5 == 0:\n",
        "        print(step + 1, end=', ')\n",
        "\n",
        "      # Convolutions\n",
        "      # It performs the convolution on the current frame, then pools.\n",
        "      # There is no ReLU activation function needed, because it uses spikes!\n",
        "      out = self.conv1(x[step])\n",
        "      out = self.pool(out)\n",
        "      spk_c1, mem_c1 = self.lifc1(out, mem_c1)\n",
        "      out = self.conv2(spk_c1)\n",
        "      out = self.pool(out)\n",
        "      spk_c2, mem_c2 = self.lifc2(out, mem_c2)\n",
        "      out = self.conv3(spk_c2)\n",
        "      out = self.pool(out)\n",
        "      spk_c3, mem_c3 = self.lifc3(out, mem_c3)\n",
        "\n",
        "      # FC\n",
        "      out = spk_c3.view(-1, self.fc_input_size) # Flatten\n",
        "      out = self.lin1(out)\n",
        "      spk_1, mem_1 = self.lif1(out, mem_1)\n",
        "      out = self.lin2(spk_1)\n",
        "      spk_2, mem_2 = self.lif2(out, mem_2)\n",
        "      out = self.lin3(spk_2)\n",
        "      spk_3, mem_3 = self.lif2(out, mem_3)\n",
        "      out = self.lin4(spk_3)\n",
        "      spk_4, mem_4= self.lif4(out, mem_4)\n",
        "      # Keep track of the spikes from the last layer.\n",
        "      spk_rec.append(spk_4)\n",
        "\n",
        "    # Return the record of the spikes\n",
        "    return torch.stack(spk_rec, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SS7cTnvONYS"
      },
      "source": [
        "Now that the model is defined, you can create it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rdeCqB9N_iw"
      },
      "outputs": [],
      "source": [
        "spike_grad = surrogate.fast_sigmoid(slope=25) # the surrogate gradient\n",
        "beta = 0.9 # decay rate\n",
        "\n",
        "# this is for using cuda\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Device: {device}')\n",
        "model = SpkNet(input_size, hidden_size, output_size, beta, spike_grad).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpB3CQI5Pbtk"
      },
      "source": [
        "# Loss and optimizer\n",
        "\n",
        "Yay you created the model! Now, it needs a loss function, and also an optimizer.\n",
        "\n",
        "The correct output class should be the one with the most spikes, so it makes sense for the loss to be minimized when all the spikes happen for the correct output class. However, this could result in weights getting set to zero causing dead neurons, so instead, the loss will aim for a certain percent of spikes in the correct class, with the rest being for the incorrect class.\n",
        "\n",
        "The loss will be mean squared error and the optimizer will be Adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LFtaJcCWOh-t"
      },
      "outputs": [],
      "source": [
        "# Learning rate\n",
        "learning_rate = 0.0001\n",
        "target_correct = 0.8\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = SF.mse_count_loss(correct_rate=target_correct, incorrect_rate=1-target_correct)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSkd7qO2nIsu"
      },
      "source": [
        "## Training\n",
        "Now, the model is created and you are ready to train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAkd_q_tnR0I"
      },
      "outputs": [],
      "source": [
        "import datetime # so we can see how long each batch is taking\n",
        "save_checkpoints = True\n",
        "\n",
        "# loading and saving the model:\n",
        "# you can import a model that is saved already\n",
        "load_model_path = None # './models/snn/model'\n",
        "# you'll save checkpoints to ./models/snn/epoch{epoch}, and save the most recent to ./models/snn/model\n",
        "save_model_path = './models/snn'\n",
        "\n",
        "\n",
        "# function for saving\n",
        "import os\n",
        "def save(epoch, model, optimizer, path):\n",
        "  checkpoint = {\n",
        "    'epoch': epoch,\n",
        "    'model_state': model.state_dict(),\n",
        "    'optim_state': optimizer.state_dict()\n",
        "  }\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "  torch.save(checkpoint, path)\n",
        "  print(f'Saved to {path}')\n",
        "\n",
        "starting_epoch = 0\n",
        "# load existing model\n",
        "if load_model_path is not None:\n",
        "  checkpoint = torch.load(load_model_path, map_location=torch.device('cpu'))\n",
        "  starting_epoch = checkpoint['epoch']\n",
        "  model.load_state_dict(checkpoint['model_state'])\n",
        "  optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "  print(f'Starting from after epoch {starting_epoch}')\n",
        "else:\n",
        "  print('New model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q_kGK0PnteQ"
      },
      "source": [
        "And now you can do a training loop. Also, display what a sample is like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UYkKPPFPqu6i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "# @title define function for animation\n",
        "def show_sample(data, interval=30):\n",
        "  animation = plot_animation(interval, frames=data)\n",
        "  return animation\n",
        "\n",
        "# from https://github.com/neuromorphs/tonic/blob/develop/tonic/utils.py\n",
        "from typing import Tuple\n",
        "def plot_animation(interval, frames: np.ndarray, figsize: Tuple[int, int] = (5, 5)):\n",
        "  try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib import animation\n",
        "  except ImportError:\n",
        "    raise ImportError(\n",
        "      \"Please install the matplotlib package to plot events. This is an optional dependency.\"\n",
        "    )\n",
        "  fig = plt.figure(figsize=figsize)\n",
        "  if frames.shape[1] == 2:\n",
        "    rgb = np.zeros((frames.shape[0], 3, *frames.shape[2:]))\n",
        "    rgb[:, 1:, ...] = frames\n",
        "    frames = rgb\n",
        "  if frames.shape[1] in [1, 2, 3]:\n",
        "    frames = np.moveaxis(frames, 1, 3)\n",
        "  ax = plt.imshow(frames[0])\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  def animate(frame):\n",
        "    ax.set_data(frame)\n",
        "    return ax\n",
        "\n",
        "  anim = animation.FuncAnimation(fig, animate, frames=frames, interval=interval)\n",
        "  return anim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaII5ZG9nymd"
      },
      "outputs": [],
      "source": [
        "model.train() # this is important to set it to training mode\n",
        "\n",
        "# record the accuracy\n",
        "accuracies = []\n",
        "for epoch in range(starting_epoch, num_epochs):\n",
        "  print(datetime.datetime.now())\n",
        "\n",
        "  # trainloader gives one batch at a time\n",
        "  for i, (data, targets) in enumerate(trainloader):\n",
        "    # let's plot the first sample in the first batch of the first epoch:\n",
        "    if epoch == starting_epoch and i == 0:\n",
        "      data_animate = data.clone() / 1.5\n",
        "      data_animate[data_animate > 1] = 1\n",
        "      print(f'Target: {classes[targets[0]]}')\n",
        "      anim = show_sample(data_animate[:, 0, :, :, :], interval=30)\n",
        "      HTML(anim.to_jshtml())\n",
        "\n",
        "    # forward pass\n",
        "    # move the tensors onto the device\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    # run the model on the input to get the spikes record\n",
        "    spk_rec = model(data)\n",
        "    # get the loss\n",
        "    loss = criterion(spk_rec, targets)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    accuracy = SF.accuracy_rate(spk_rec, targets)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    if i % 1 == 0:\n",
        "      print(f'Epoch {epoch + 1}/{num_epochs}: Batch {i + 1}/{len(trainloader)}: Loss: {loss.item():.2f}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "  if save_checkpoints:\n",
        "    save(epoch + 1, model, optimizer, save_model_path + f'/epoch{epoch + 1}')\n",
        "    save(epoch + 1, model, optimizer, save_model_path + '/model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F_Bmj1H5VSVv"
      },
      "outputs": [],
      "source": [
        "# @title If the animation didn't show up, try this\n",
        "anim = show_sample(data_animate[:, 0, :, :, :], interval=30)\n",
        "HTML(anim.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X30OSSk0ossR"
      },
      "source": [
        "Let's see how the training accuracy changed over training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-CkIdh2osaU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(starting_epoch, starting_epoch + num_epochs)), accuracies)\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubHrR9VeliEc"
      },
      "source": [
        "Congrats, you trained a spiking neural network to read lips! Now you can evaluate it with the test dataset to see how good it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuSZN-_jlqTc"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqB9od1NlrKp"
      },
      "outputs": [],
      "source": [
        "# switch to eval mode\n",
        "model.eval()\n",
        "\n",
        "# it doesn't need to keep track of gradients because it is not learning here\n",
        "with torch.no_grad():\n",
        "  # to keep track of its accuracy\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # this is to see how well it did on each word\n",
        "  classes_correct = [0] * len(classes)\n",
        "  classes_total = [0] * len(classes)\n",
        "  # iterate one batch at a time\n",
        "  for i, (data, targets) in enumerate(testloader):\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    # get the spiking record\n",
        "    spk_rec = model(data)\n",
        "    loss = criterion(spk_rec, targets)\n",
        "    total += batch_size\n",
        "    for j in range(batch_size):\n",
        "      single_spk_rec = spk_rec[:, j, :]\n",
        "      # get the prediction (the class that had the most spikes)\n",
        "      _, prediction = torch.max(sum(single_spk_rec), 0)\n",
        "      target = targets[j]\n",
        "      classes_total[target] += 1\n",
        "      if prediction == target:\n",
        "        classes_correct[target] += 1\n",
        "        correct += 1\n",
        "    if i % 1 == 0:\n",
        "      print(f'Batch {i + 1}/{len(testloader)}: Loss: {loss.item():.2f}')\n",
        "      print(f'Current total: {total}. Current Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "  print(f'Final Test Accuracy: {100 * correct / total:.2f}%')\n",
        "  for i in range(100):\n",
        "    if classes_total[i] != 0:\n",
        "      print(f'{classes[i]}: {100 * classes_correct[i] / classes_total[i]:.2f}%', end=', ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXIvszO-mdIL"
      },
      "source": [
        "Hopefully it did ok! I trained it for 200 epochs and it got around 16% accuracy on the test set. Can this be improved though?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMCtq7yTmmLW"
      },
      "source": [
        "## Other ideas\n",
        "Now that you made a spiking neural network model for this, you can try other methods to see how other methods do! For example, you could make a 3D CNN which I will show next. A disadvantage of this is that it takes fixed-length input, so all the videos need to be padded to be the same length, which is not good for this case where a video could be of any length. However, it got to 28% accuracy and in fewer epochs than the spiking neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij1HDCa6VnZx"
      },
      "source": [
        "Let's define the model for the 3D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x8RCDVTyVpCm"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Convolutions\n",
        "    # The numbers I chose here are so the output is not too big but still works\n",
        "    self.pool = nn.MaxPool3d(3)\n",
        "    self.pool2 = nn.MaxPool3d(2)\n",
        "\n",
        "    self.conv1 = nn.Conv3d(2, 4, 3, padding='same')\n",
        "    self.conv2 = nn.Conv3d(4, 8, 3, padding='same')\n",
        "    self.conv3 = nn.Conv3d(8, 16, 3, padding='same')\n",
        "    self.conv4 = nn.Conv3d(16, 32, 3, padding='same')\n",
        "\n",
        "\n",
        "    # FC\n",
        "    self.fc_input_size = 288\n",
        "    self.hidden_size = 150\n",
        "    self.lin1 = nn.Linear(self.fc_input_size, self.hidden_size)\n",
        "    self.lin2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.lin3 = nn.Linear(self.hidden_size, 100)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Now, there is no loop over the timesteps. It is doing convolutions over time and the image at once, like a 3D volume\n",
        "    # 3d convs\n",
        "    x = F.relu(self.pool(self.conv1(x)))\n",
        "    x = F.relu(self.pool(self.conv2(x)))\n",
        "    x = F.relu(self.pool2(self.conv3(x)))\n",
        "    x = F.relu(self.pool2(self.conv4(x)))\n",
        "\n",
        "    # fc\n",
        "    x = x.view(batch_size, self.fc_input_size)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = F.relu(self.lin2(x))\n",
        "    x = self.lin3(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model2 = ConvNet().to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "# now the loss is just cross entropy loss, as there's not spiking anymore.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, betas=(0.9, 0.99))\n",
        "\n",
        "\n",
        "# loading a model\n",
        "load_model_path = None # './models/cnn/model'\n",
        "save_model_path = './models/cnn'\n",
        "\n",
        "starting_epoch = 0\n",
        "if load_model_path is not None:\n",
        "  checkpoint = torch.load(load_model_path, map_location=torch.device('cpu'))\n",
        "  starting_epoch = checkpoint['epoch']\n",
        "  model2.load_state_dict(checkpoint['model_state'])\n",
        "  optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "  print(f'Starting from after epoch {starting_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQVy0sPrWYTc"
      },
      "source": [
        "We can't just run this now though, because the data has to be in a different format. The CNN takes in a fixed length input, and we also have to change the shape of it so batches comes before timestep. Here is a function to pad or crop all the videos to 70 frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AXy2U_iRWvnj"
      },
      "outputs": [],
      "source": [
        "def custom_pad(batch, max_length=70, image_size=128):\n",
        "  # This is an empty frame\n",
        "  pad = torch.zeros(2, image_size, image_size)\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(batch_size):\n",
        "    y.append(batch[i][1])\n",
        "    if len(batch[i][0]) > max_length: # too long: just take the first 70 frames\n",
        "      x.append(batch[i][0][:max_length])\n",
        "    elif len(batch[i][0] < max_length):  # too short: append empty frames\n",
        "      x.append(torch.cat((batch[i][0], pad.repeat(max_length - len(batch[i][0]), 1, 1, 1)), 0))\n",
        "    else:\n",
        "      x.append(batch[i][0]) # just right length\n",
        "  return (torch.stack(x, dim=0), torch.LongTensor(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RUiQnazXNBW"
      },
      "source": [
        "Now, recreate the trainloader and testloader, using this padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "M1l9ye9TW-QU"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=custom_pad, shuffle=True, drop_last=True)\n",
        "testloader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=custom_pad, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-QZfCafXVG3"
      },
      "source": [
        "Now, you can train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLV5VE4YXXYK"
      },
      "outputs": [],
      "source": [
        "# switch to training mode\n",
        "model2.train()\n",
        "print('Training')\n",
        "for epoch in range(starting_epoch, num_epochs):\n",
        "  print(datetime.datetime.now())\n",
        "  for i, (data, targets) in enumerate(trainloader):\n",
        "    # forward pass\n",
        "    # switch the batch and timestep dimensions\n",
        "    data = torch.permute(data, (0, 2, 1, 3, 4))\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    out = model2(data)\n",
        "    loss = criterion(out, targets)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 1 == 0:\n",
        "      print(f'Epoch {epoch + 1}/{num_epochs}: Batch {i + 1}/{len(trainloader)}: Loss: {loss.item():.2f}')\n",
        "\n",
        "  if save_checkpoints:\n",
        "    save(epoch + 1, model2, optimizer, save_model_path + f'/epoch{epoch + 1}')\n",
        "    save(epoch + 1, model2, optimizer, save_model_path + '/model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ura0cvps40"
      },
      "source": [
        "# Combining 3D CNN with SNN\n",
        "Given that both a 3D CNN and a spiking neural network worked, it might be interesting to try combining them! However, the input will still need to be fixed length because of the 3D CNN, but then it will use the SNN on the output. Also, let's add more frames because it is going to be shrunk down by the 3D CNN. You might need to decrease batch size more because the samples are bigger."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50"
      ],
      "metadata": {
        "id": "gAgTiEZD4qHO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now each sample will have 350 frames\n",
        "def custom_pad(batch, max_length=350, image_size=128):\n",
        "  # This is an empty frame\n",
        "  pad = torch.zeros(2, image_size, image_size)\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(batch_size):\n",
        "    y.append(batch[i][1])\n",
        "    if len(batch[i][0]) > max_length: # too long: just take the first 350 frames\n",
        "      x.append(batch[i][0][:max_length])\n",
        "    elif len(batch[i][0] < max_length):  # too short: append empty frames\n",
        "      x.append(torch.cat((batch[i][0], pad.repeat(max_length - len(batch[i][0]), 1, 1, 1)), 0))\n",
        "    else:\n",
        "      x.append(batch[i][0]) # just right length\n",
        "  return (torch.stack(x, dim=0), torch.LongTensor(y))"
      ],
      "metadata": {
        "id": "Xbw2W_JZ0zVB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's redo changing the events to frames, this time shrinking the time window to give it more resolution"
      ],
      "metadata": {
        "id": "wahubYtd08EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same code from before, but with lower time window and using the custom function above\n",
        "# Get the sensor_size\n",
        "sensor_size = tonic.datasets.DVSLip.sensor_size # should be (128, 128, 2)\n",
        "print(f'Sensor size: {sensor_size}')\n",
        "\n",
        "# The tonic.transforms.Compose is to apply transforms sequentially.\n",
        "# Denoise is used to reduce the noise. If a nearby pixel does not have an event within filter_time from this event, it gets ignored.\n",
        "# ToFrame is super important! The data is formatted right now as a sequence of events which is a tuple, but we want a sequence of frames\n",
        "# The time window is the window across which events are combined to make a single frame. Right now, there are hundreds of thousands of timesteps which you saw when you looked at the last event in the first sample.\n",
        "frame_transform = tonic.transforms.Compose([tonic.transforms.Denoise(filter_time=50000),\n",
        "                                            tonic.transforms.ToFrame(sensor_size=sensor_size,\n",
        "                                                                     time_window=6000)]) # the time window is 5x less\n",
        "\n",
        "# Now, we create the trainset (and testset) applying these transforms\n",
        "trainset = tonic.datasets.DVSLip(save_to=\"./data\", transform=frame_transform, train=True)\n",
        "testset = tonic.datasets.DVSLip(save_to=\"./data\", transform=frame_transform, train=False)\n",
        "\n",
        "# Ok now time to switch to pytorch\n",
        "\n",
        "# To convert to float\n",
        "class ToFloat(object):\n",
        "  def __call__(self, sample):\n",
        "    return sample.float()\n",
        "\n",
        "# The first is to convert the input which is a numpy array into a torch tensor.\n",
        "# The next one converts it to float, because the next one after that is normalizing the data and it takes floats.\n",
        "# The last transform is done to make the data normalized\n",
        "torch_transform = torchvision.transforms.Compose([\n",
        "    torch.from_numpy,\n",
        "    ToFloat(),\n",
        "    torchvision.transforms.Normalize((0, 0), (1, 1))\n",
        "    ])\n",
        "\n",
        "# By using this to cache the data, it will speed up training.\n",
        "# It may still take a long time for the first epoch, but then after that, it will go way faster.\n",
        "cached_trainset = MemoryCachedDataset(trainset, transform=torch_transform)\n",
        "cached_testset = MemoryCachedDataset(testset, transform=torch_transform)\n",
        "\n",
        "trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=custom_pad, shuffle=True, drop_last=True)\n",
        "testloader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=custom_pad, shuffle=True, drop_last=True)\n",
        "\n",
        "classes = trainset.classes\n",
        "print(f'Training batches: {len(trainloader)}')\n",
        "print(f'Testing batches: {len(testloader)}')"
      ],
      "metadata": {
        "id": "QoF14L7E0l-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3R0yVrcppsFI"
      },
      "outputs": [],
      "source": [
        "class CSNN(nn.Module):\n",
        "  def __init__(self, beta, spike_grad):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    # Convolutions\n",
        "    # The numbers I chose here are so the output is not too big but still works\n",
        "    self.pool = nn.MaxPool3d(3)\n",
        "    self.pool2 = nn.MaxPool3d(2)\n",
        "\n",
        "    self.conv1 = nn.Conv3d(2, 4, 3, padding='same')\n",
        "    self.conv2 = nn.Conv3d(4, 8, 3, padding='same')\n",
        "    self.conv3 = nn.Conv3d(8, 8, 3, padding='same')\n",
        "\n",
        "\n",
        "    # FC\n",
        "    hidden_size = 100\n",
        "    output_size = 100\n",
        "    self.lin1 = nn.Linear(2048, hidden_size)\n",
        "    self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.lin3 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "    self.lin4 = nn.Linear(hidden_size, output_size)\n",
        "    self.lif4 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Now, there is no loop over the timesteps. It is doing convolutions over time and the image at once, like a 3D volume\n",
        "    # 3d convs\n",
        "    x = F.relu(self.pool2(self.conv1(x)))\n",
        "    x = F.relu(self.pool2(self.conv2(x)))\n",
        "    x = F.relu(self.pool2(self.conv3(x)))\n",
        "\n",
        "    # [50, 8, 43, 16, 16])\n",
        "    new_x = torch.permute(x, (2, 0, 1, 3, 4))\n",
        "    # [43, 50, 8, 16, 16])\n",
        "\n",
        "    # spiking fc part\n",
        "    spk_rec = []\n",
        "    mem_1 = self.lif1.init_leaky()\n",
        "    mem_2 = self.lif2.init_leaky()\n",
        "    mem_3 = self.lif3.init_leaky()\n",
        "    mem_4 = self.lif4.init_leaky()\n",
        "\n",
        "    for step in range(43):\n",
        "      out = new_x[step].reshape(-1, 8 * 16 * 16)\n",
        "      out = self.lin1(out)\n",
        "      spk_1, mem_1 = self.lif1(out, mem_1)\n",
        "      out = self.lin2(spk_1)\n",
        "      spk_2, mem_2 = self.lif2(out, mem_2)\n",
        "      out = self.lin3(spk_2)\n",
        "      spk_3, mem_3 = self.lif2(out, mem_3)\n",
        "      out = self.lin4(spk_3)\n",
        "      spk_4, mem_4= self.lif4(out, mem_4)\n",
        "      spk_rec.append(spk_4)\n",
        "\n",
        "    return torch.stack(spk_rec, dim=0)\n",
        "\n",
        "model3 = CSNN(beta, spike_grad).to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = SF.mse_count_loss(correct_rate=target_correct, incorrect_rate=1-target_correct)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))\n",
        "\n",
        "\n",
        "# loading a model\n",
        "load_model_path = None # './models/csnn/model'\n",
        "save_model_path = './models/csnn'\n",
        "\n",
        "starting_epoch = 0\n",
        "if load_model_path is not None:\n",
        "  checkpoint = torch.load(load_model_path, map_location=torch.device('cpu'))\n",
        "  starting_epoch = checkpoint['epoch']\n",
        "  model3.load_state_dict(checkpoint['model_state'])\n",
        "  optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "  print(f'Starting from after epoch {starting_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, try training!"
      ],
      "metadata": {
        "id": "DlXL240q-utH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# switch to training mode\n",
        "model3.train()\n",
        "accuracies = []\n",
        "\n",
        "print('Training')\n",
        "for epoch in range(starting_epoch, num_epochs):\n",
        "  print(datetime.datetime.now())\n",
        "  for i, (data, targets) in enumerate(trainloader):\n",
        "    # forward pass\n",
        "    # switch the batch and timestep dimensions\n",
        "    data = torch.permute(data, (0, 2, 1, 3, 4))\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    spk_rec = model3(data)\n",
        "    loss = criterion(spk_rec, targets)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    accuracy = SF.accuracy_rate(spk_rec, targets)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    if i % 1 == 0:\n",
        "      print(f'Epoch {epoch + 1}/{num_epochs}: Batch {i + 1}/{len(trainloader)}: Loss: {loss.item():.2f}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "  if save_checkpoints:\n",
        "    save(epoch + 1, model3, optimizer, save_model_path + f'/epoch{epoch + 1}')\n",
        "    save(epoch + 1, model3, optimizer, save_model_path + '/model')"
      ],
      "metadata": {
        "id": "ECaLDI2i-m8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's not really learning though, so maybe the other models were better."
      ],
      "metadata": {
        "id": "znCpii9jFg9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot accuracy"
      ],
      "metadata": {
        "id": "AwhJinxj_t8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(list(range(starting_epoch, starting_epoch + num_epochs)), accuracies)\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')"
      ],
      "metadata": {
        "id": "Z9gf2N_n_tfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now, evaluate:"
      ],
      "metadata": {
        "id": "l91jqVyp_B59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# switch to eval mode\n",
        "model.eval()\n",
        "\n",
        "# it doesn't need to keep track of gradients because it is not learning here\n",
        "with torch.no_grad():\n",
        "  # to keep track of its accuracy\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # this is to see how well it did on each word\n",
        "  classes_correct = [0] * len(classes)\n",
        "  classes_total = [0] * len(classes)\n",
        "  # iterate one batch at a time\n",
        "  for i, (data, targets) in enumerate(testloader):\n",
        "    data = torch.permute(data, (0, 2, 1, 3, 4))\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    # get the spiking record\n",
        "    spk_rec = model3(data)\n",
        "    loss = criterion(spk_rec, targets)\n",
        "    total += batch_size\n",
        "    for j in range(batch_size):\n",
        "      single_spk_rec = spk_rec[:, j, :]\n",
        "      # get the prediction (the class that had the most spikes)\n",
        "      _, prediction = torch.max(sum(single_spk_rec), 0)\n",
        "      target = targets[j]\n",
        "      classes_total[target] += 1\n",
        "      if prediction == target:\n",
        "        classes_correct[target] += 1\n",
        "        correct += 1\n",
        "    if i % 1 == 0:\n",
        "      print(f'Batch {i + 1}/{len(testloader)}: Loss: {loss.item():.2f}')\n",
        "      print(f'Current total: {total}. Current Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "  print(f'Final Test Accuracy: {100 * correct / total:.2f}%')\n",
        "  for i in range(100):\n",
        "    if classes_total[i] != 0:\n",
        "      print(f'{classes[i]}: {100 * classes_correct[i] / classes_total[i]:.2f}%', end=', ')"
      ],
      "metadata": {
        "id": "ut2CAxtC_Frv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End\n",
        "You finished the tutorial! I hope you enjoyed it and learned!"
      ],
      "metadata": {
        "id": "s7ZCHhrl_cp5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ9JQmazmwG9"
      },
      "source": [
        "Group contribution statement: I worked on this tutorial on my own"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}